{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7de520-7e2d-46a8-9801-c8447f673484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import torch.onnx\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from model import ResNet\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "columns = 3\n",
    "rows = 3\n",
    "channels = 16\n",
    "layers = 5\n",
    "epochs = 100\n",
    "training_batch_size = 64\n",
    "inference_batch_size = 256\n",
    "kl_loss_scale = 0.1\n",
    "\n",
    "data_folder = \"../data\"\n",
    "models_folder = \"../models\"\n",
    "generation = 1\n",
    "\n",
    "class Snapshots(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        self.data = [[], [], [], []]\n",
    "        i = 0\n",
    "        with open(file_name) as f:\n",
    "            for line in f.readlines():\n",
    "                if line.strip() == \"\":\n",
    "                    i = 0\n",
    "                    continue\n",
    "\n",
    "                t = torch.tensor([float(x) for x in line.split(\", \")])\n",
    "\n",
    "                if i == 0:\n",
    "                    t = t.view(7, columns, rows)\n",
    "                self.data[i].append(t)\n",
    "                i += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return [self.data[x][index] for x in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17deff99-8d43-42c5-998d-3a2a018cc1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(wp_out, sp_out, vs_out, wp_label, sp_label, vs_label):\n",
    "    kl_div = nn.KLDivLoss(reduction='sum')\n",
    "    mse = nn.MSELoss(reduction='sum')\n",
    "    \n",
    "    # Concatenate the outputs to form the complete action distribution\n",
    "    actions_out = torch.cat([wp_out, sp_out], dim=1)\n",
    "    # Apply log_softmax to convert to log probabilities\n",
    "    log_probs = F.log_softmax(actions_out, dim=1)\n",
    "    \n",
    "    # Concatenate the labels to form the complete target distribution\n",
    "    actions_label = torch.cat([wp_label, sp_label], dim=1)\n",
    "    \n",
    "    # Compute the KL divergence loss\n",
    "    kl_loss = kl_loss_scale * kl_div(log_probs, actions_label)\n",
    "    \n",
    "    # Compute the MSE loss for the scalar output\n",
    "    mse_loss = mse(vs_out, vs_label)\n",
    "\n",
    "    return (kl_loss, mse_loss)\n",
    "\n",
    "\n",
    "def save_model(model, folder):\n",
    "    torch.save(model, f\"{folder}/model_{generation}.pt\")\n",
    "    input_names = [\"States\"]\n",
    "    output_names = [\"WallPriors\", \"StepPriors\", \"Values\"]\n",
    "    dummy_input = torch.randn(inference_batch_size, 7, columns, rows).to(device)\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        f\"{folder}/model_{generation}.onnx\",\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aba22da-d7c8-4214-9b14-102331726bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(f\"{models_folder}/model_{generation - 1}.pt\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cae0251-928b-44eb-bfb2-4a400bba1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_window = range((generation - 1) // 2, generation)\n",
    "snapshots = torch.utils.data.ConcatDataset(\n",
    "    [Snapshots(f\"{data_folder}/snapshots_{i}.csv\") for i in training_window]\n",
    ")\n",
    "training_data, eval_data = torch.utils.data.random_split(snapshots, [0.8, 0.2])\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_data,\n",
    "    batch_size=training_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=training_batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5c56510-de5b-4897-bda8-d95fd99ad212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tensor(mat, cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Plots a 2D PyTorch tensor as an n x n grid of squares with colors representing the tensor values.\n",
    "\n",
    "    Parameters:\n",
    "    - mat: 2D PyTorch tensor of floats.\n",
    "    - cmap: Colormap for visualizing the values in the tensor.\n",
    "    \"\"\"\n",
    "    # Ensure mat is a 2D tensor\n",
    "    if mat.dim() != 2:\n",
    "        raise ValueError(\"Input tensor must be 2D\")\n",
    "\n",
    "    # Convert the tensor to a NumPy array\n",
    "    matrix = mat.numpy()\n",
    "\n",
    "    # Plotting the matrix\n",
    "    plt.figure(figsize=(6,6))  # Adjust the figure size as needed\n",
    "    plt.imshow(matrix, cmap=cmap, interpolation='nearest')  # Use specified colormap\n",
    "    plt.colorbar()  # Show color scale\n",
    "    plt.xticks(range(matrix.shape[0]))  # Adjust ticks based on tensor size\n",
    "    plt.yticks(range(matrix.shape[1]))\n",
    "    plt.grid(False)  # Turn off the grid\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "812a3b40-e684-4e6c-a626-7aa278ac4bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfEAAAHqCAYAAAAUI3clAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvWklEQVR4nO3df3CUVZ7v8U8nkG5l6F4QSaAIMTqukM2Mkg7m14C6MwYzoyWza5EZa4LewtJcwDGmtmrNgCOy1ka3HEUcEqVGyWWniLkOIlg3LrQ7JQkmuNfcxNkquV5mxUmGTYvhrmlghwS6n/sH0temk4fu2J1+ns77VfXUmJPTp0/LzHz5nPOcpx2GYRgCAAC2k5HqCQAAgImhiAMAYFMUcQAAbIoiDgCATVHEAQCwKYo4AAA2RREHAMCmKOIAANjUtFRPAACAsZw9e1ajo6NJGTsrK0sulyspY08mijgAwHLOnj2r/LxvyH8imJTxc3JydOzYMdsXcoo4AMByRkdH5T8R1LGePLlnJnbnN3AqpHzvHzQ6OkoRBwAgWdwzMxJexNMJRRwAYFlBI6Rggr+mK2iEEjtgCvHXGwAAbIokDgCwrJAMhZTYKJ7o8VKJJA4AgE2RxAEAlhVSSInewU78iKlDEgcAwKZI4gAAywoahoJGYvewEz1eKlHEAQCWxY1t5lhOBwDApkjiAADLCslQkCQ+LpI4AAA2RRIHAFgWe+LmSOIAANgUSRwAYFkcMTNHEgcAwKZI4gAAywp9eSV6zHRBEQcAWFYwCUfMEj1eKrGcDgCATZHEAQCWFTQuXIkeM12QxAEAsCmSOADAsrixzRxJHAAAmyKJAwAsKySHgnIkfMx0QRIHAMCmSOIAAMsKGReuRI+ZLijiAADLCiZhOT3R46USy+kAANgUSRwAYFkkcXMkcQAAbIokDgCwrJDhUMhI8BGzBI+XSiRxAABsiiQOALAs9sTNkcQBALApkjgAwLKCylAwwXkzmNDRUosiDgCwLCMJN7YZ3NgGAABSjSQOALAsbmwzRxIHAMCmSOIAAMsKGhkKGgm+sS2NvsWMJA4AQAyampqUn58vl8slr9erzs7OmF733nvvadq0abrpppuifrd7924VFBTI6XSqoKBAe/bsiWtOk57EQ6GQ/v3f/10zZ86Uw5E++xIAMNUYhqFTp05p/vz5yshITiYMyaFQgvNmSPFH8ba2NtXV1ampqUkVFRV6+eWXVVVVpY8++kgLFy4c93XDw8NavXq1vvvd7+qzzz6L+F13d7eqq6v1d3/3d/rhD3+oPXv2aNWqVTp06JBKSkpimpfDMIxJXVj44x//qNzc3Ml8SwBAEg0MDGjBggUJHTMQCMjj8eh//O5azZiZmdCxz5wK6gff/kTDw8Nyu90xvaakpERFRUVqbm4Oty1evFgrV65UY2PjuK/70Y9+pOuvv16ZmZl688031dfXF/5ddXW1AoGA3n777XDbHXfcoVmzZqm1tTWmeU16Ep85c6YkacGmjcpwuSb77ZECOe+l0QYUYnLlWx+kegqYBOd1TofUHv7/9WRI5t3pgUAgot3pdMrpdEb1Hx0dVU9Pjx577LGI9srKSnV1dY37Pjt27NC//du/6de//rWeeuqpqN93d3fr0UcfjWhbsWKFtmzZEutHmfwifnEJPcPloohPEdOmU8SnmmmO6ameAibDl//TTubWaHJubLsw8UtXhZ944glt2rQpqv/Q0JCCwaCys7Mj2rOzs+X3+8d8j6NHj+qxxx5TZ2enpk0bu9T6/f64xhwLd6cDAKakgYGBiOX0sVL4V136lxXDMMb8C0wwGNS9996rJ598Un/+53+ekDHHQxEHAFjWhRvbEvx94l+O53a7Y9oTnzNnjjIzM6MS8okTJ6KStCSdOnVKH3zwgXp7e7V+/foL7xkKyTAMTZs2TQcOHNBf/uVfKicnJ+Yxx8MRMwAATGRlZcnr9crn80W0+3w+lZeXR/V3u93613/9V/X19YWv2tpa3XDDDerr6wvfeV5WVhY15oEDB8YcczwkcQCAZYWS8C1mEzliVl9fr5qaGhUXF6usrEzbt29Xf3+/amtrJUkNDQ06fvy4du7cqYyMDBUWFka8fu7cuXK5XBHtjzzyiJYvX65nnnlGd999t/bu3at33nlHhw4dinleFHEAAC6jurpaJ0+e1ObNmzU4OKjCwkK1t7crLy9PkjQ4OKj+/v64xiwvL9drr72mjRs36vHHH9d1112ntra2mM+ISyk4J37x7N/Cp5/i7vQpYn4Hd6dPNVfueT/VU8AkOG+c07vaG9d561hdrBWv9RXoygSfE//PU0H96KaPkjLvycaeOAAANsVyOgDAskLKsMRjV62KIg4AsKyg4VDQSPAT2xI8XiqxnA4AgE2RxAEAlhVMwhGzYBotp5PEAQCwKZI4AMCyQkaGQgn+ApTQ5J6sTiqSOAAANkUSBwBYFnvi5kjiAADYFEkcAGBZISX+XHcooaOlFkUcAGBZyXliW/osQqfPJwEAYIohiQMALCtoZCiY4CNmiR4vldLnkwAAMMWQxAEAlhWSQyEl+sY2vgAFAACkGEkcAGBZ7ImbS59PAgDAFEMSBwBYVnIeu5o++ZUiDgCwrJDhUCjRT2xL8HiplD5/HQEAYIohiQMALCuUhOV0HrsKAABSjiQOALCskJGhUIKPhCV6vFRKn08CAMAUQxIHAFhWUA4FE/yY1ESPl0okcQAAbIokDgCwLPbEzaXPJwEAYIohiQMALCuoxO9hBxM6WmpRxAEAlsVyurn0+SQAAEwxJHEAgGXxfeLm0ueTAAAwxZDEAQCWZcihUIJvbDN42AsAAEg1kjgAwLLYEzeXPp8EAIAphiQOALCskOFQyEjsHnaix0slijgAwLKCylAwwYvGiR4vldLnkwAAkERNTU3Kz8+Xy+WS1+tVZ2fnuH0PHTqkiooKXXXVVbriiiu0aNEiPf/88xF9Wlpa5HA4oq6zZ8/GPCeSOADAsqyynN7W1qa6ujo1NTWpoqJCL7/8sqqqqvTRRx9p4cKFUf1nzJih9evX69vf/rZmzJihQ4cO6aGHHtKMGTP04IMPhvu53W59/PHHEa91uVwxz4siDgDAZTz33HNas2aNHnjgAUnSli1btH//fjU3N6uxsTGq/5IlS7RkyZLwz9dcc43eeOMNdXZ2RhRxh8OhnJycCc+L5XQAgGWFlJGUS5ICgUDENTIyMuYcRkdH1dPTo8rKyoj2yspKdXV1xfQ5ent71dXVpVtuuSWi/fTp08rLy9OCBQt05513qre3N65/PxRxAMCUlJubK4/HE77GStSSNDQ0pGAwqOzs7Ij27Oxs+f1+0/dYsGCBnE6niouLtW7dunCSl6RFixappaVF+/btU2trq1wulyoqKnT06NGYPwPL6QAAywoaDgUTvCd+cbyBgQG53e5wu9PpNH2dwxE5D8Mwotou1dnZqdOnT+vw4cN67LHH9M1vflM//vGPJUmlpaUqLS0N962oqFBRUZFefPFFbd26NabPQhEHAExJbrc7ooiPZ86cOcrMzIxK3SdOnIhK55fKz8+XJH3rW9/SZ599pk2bNoWL+KUyMjK0dOnSuJI4y+kAAMu6eHd6oq94ZGVlyev1yufzRbT7fD6Vl5fHPI5hGOPuu1/8fV9fn+bNmxfzmBMq4vGclQMAYKIMI0OhBF/GBJ6dXl9fr1/96ld69dVXdeTIET366KPq7+9XbW2tJKmhoUGrV68O99+2bZveeustHT16VEePHtWOHTv07LPP6ic/+Um4z5NPPqn9+/frk08+UV9fn9asWaO+vr7wmLGIezk93rNyAADYXXV1tU6ePKnNmzdrcHBQhYWFam9vV15eniRpcHBQ/f394f6hUEgNDQ06duyYpk2bpuuuu05PP/20HnrooXCfL774Qg8++KD8fr88Ho+WLFmijo4O3XzzzTHPy2EYhhHPBykpKVFRUZGam5vDbYsXL9bKlSvHvbPvqwKBgDwejxY+/ZQy4jjQDvua3xHXf8WQBq7c836qp4BJcN44p3e1V8PDwzHtLcfjYq1Yc3CVsr4xPaFjj54+p1du+e9Jmfdki2tNIRFn5QAAQGLEtZw+kbNyIyMjERv5gUBgAtMEAExFISPx3zoWSqPFwQnd2BbPWbnGxsaIw/S5ubkTeUsAAHCJuIr4RM7KNTQ0aHh4OHwNDAxMfLYAgCkl0XemX7zSRVyfZCJn5ZxOZ/hAfawH6wEAwOXFfcSsvr5eNTU1Ki4uVllZmbZv3x5xVg4AgEQJyaGQErwnnuDxUinuIn65s3IAACRKMp+dng4m9Oz0tWvXau3atYmeCwAAiANfgAIAsKxk3Ig2ZW9sAwAA1kESBwBYVkjxf+tYLGOmC5I4AAA2RRIHAFiWkYQjZgZJHAAApBpJHABgWSEjCXviU/2cOAAAk4EjZubS55MAADDFkMQBAJbFcro5kjgAADZFEgcAWBbfYmaOJA4AgE2RxAEAlsWeuDmSOAAANkUSBwBYFkncHEUcAGBZFHFzLKcDAGBTJHEAgGWRxM2RxAEAsCmSOADAsgwl/uEsRkJHSy2SOAAANkUSBwBYFnvi5kjiAADYFEkcAGBZJHFzFHEAgGVRxM2xnA4AgE2RxAEAlkUSN0cSBwDApkjiAADLMgyHjAQn50SPl0okcQAAbIokDgCwrJAcCX/saqLHSyWSOAAANkURBwBY1sW70xN9TURTU5Py8/Plcrnk9XrV2dk5bt9Dhw6poqJCV111la644gotWrRIzz//fFS/3bt3q6CgQE6nUwUFBdqzZ09cc6KIAwAs6+KNbYm+4tXW1qa6ujpt2LBBvb29WrZsmaqqqtTf3z9m/xkzZmj9+vXq6OjQkSNHtHHjRm3cuFHbt28P9+nu7lZ1dbVqamr04YcfqqamRqtWrdL7778f87wchmFM6reyBQIBeTweLXz6KWW4XJP51kiR+R3p9MV/iMWVe2L/PyHY13njnN7VXg0PD8vtdid07Iu14uY9j2jaDGdCxz5/ZkT/8sMX4pp3SUmJioqK1NzcHG5bvHixVq5cqcbGxpjG+Ku/+ivNmDFD//iP/yhJqq6uViAQ0Ntvvx3uc8cdd2jWrFlqbW2NaUySOADAspK5nB4IBCKukZGRMecwOjqqnp4eVVZWRrRXVlaqq6srps/R29urrq4u3XLLLeG27u7uqDFXrFgR85gSRRwAMEXl5ubK4/GEr/ES9dDQkILBoLKzsyPas7Oz5ff7Td9jwYIFcjqdKi4u1rp16/TAAw+Ef+f3+yc05ldxxAwAYFnJfNjLwMBAxHK602m+bO9wRM7DMIyotkt1dnbq9OnTOnz4sB577DF985vf1I9//OOvNeZXUcQBAFOS2+2OaU98zpw5yszMjErIJ06ciErSl8rPz5ckfetb39Jnn32mTZs2hYt4Tk7OhMb8KpbTAQCWZSRhPzzeZJ+VlSWv1yufzxfR7vP5VF5eHsdnMSL23cvKyqLGPHDgQFxjksQBALiM+vp61dTUqLi4WGVlZdq+fbv6+/tVW1srSWpoaNDx48e1c+dOSdK2bdu0cOFCLVq0SNKFc+PPPvusHn744fCYjzzyiJYvX65nnnlGd999t/bu3at33nlHhw4dinleFHEAgGUZkhJ9EHoiw1VXV+vkyZPavHmzBgcHVVhYqPb2duXl5UmSBgcHI86Mh0IhNTQ06NixY5o2bZquu+46Pf3003rooYfCfcrLy/Xaa69p48aNevzxx3Xdddepra1NJSUlMc+Lc+JIOs6JTz2cE58aJuOc+JLf1CvzysSeEw/+54h673kuKfOebCRxAIBlheSQgy9AGRdFHABgWXyfuDnuTgcAwKZI4gAAywoZDjkSnJwn+i1mVkQSBwDApkjiAADLMowkHDFLowMzJHEAAGyKJA4AsCzuTjdHEgcAwKZI4gAAyyKJm6OIAwAsiyNm5lhOBwDAplKWxEuX/m9Nn5GVqrfHJHpPBameAibZfMX+LUywr/Pnzkpv7U3qe3DEzBxJHAAAm2JPHABgWReSeKJvbEvocClFEgcAwKZI4gAAy+KImTmSOAAANkUSBwBYlvHllegx0wVFHABgWSynm2M5HQAAmyKJAwCsi/V0UyRxAABsiiQOALCuJOyJiz1xAACQaiRxAIBl8QUo5kjiAADYFEkcAGBZnBM3RxEHAFiX4Uj8jWhpVMRZTgcAwKZI4gAAy+LGNnMkcQAAbIokDgCwLh67aookDgCATZHEAQCWxREzcyRxAABsiiQOALC2NNrDTjSKOADAslhON8dyOgAANkUSBwBYF0fMTJHEAQCwKYo4AMDCHEm64tfU1KT8/Hy5XC55vV51dnaO2/eNN97Q7bffrquvvlput1tlZWXav39/RJ+WlhY5HI6o6+zZszHPiSIOAMBltLW1qa6uThs2bFBvb6+WLVumqqoq9ff3j9m/o6NDt99+u9rb29XT06PbbrtNd911l3p7eyP6ud1uDQ4ORlwulyvmebEnDgCwLovsiT/33HNas2aNHnjgAUnSli1btH//fjU3N6uxsTGq/5YtWyJ+/vu//3vt3btXb731lpYsWRJudzgcysnJiX9CXyKJAwCmpEAgEHGNjIyM2W90dFQ9PT2qrKyMaK+srFRXV1dM7xUKhXTq1CnNnj07ov306dPKy8vTggULdOedd0Yl9cuhiAMArMtI0iUpNzdXHo8nfI2VqCVpaGhIwWBQ2dnZEe3Z2dny+/0xfYxf/OIXOnPmjFatWhVuW7RokVpaWrRv3z61trbK5XKpoqJCR48ejWlMieV0AICVGY4LV6LHlDQwMCC32x1udjqdpi9zOCLnYRhGVNtYWltbtWnTJu3du1dz584Nt5eWlqq0tDT8c0VFhYqKivTiiy9q69atMX0UijgAYEpyu90RRXw8c+bMUWZmZlTqPnHiRFQ6v1RbW5vWrFmj119/Xd/73vdM+2ZkZGjp0qVxJXGW0wEAlmUYybnikZWVJa/XK5/PF9Hu8/lUXl4+7utaW1t1//33a9euXfrBD34Qw2c11NfXp3nz5sU8N5I4AACXUV9fr5qaGhUXF6usrEzbt29Xf3+/amtrJUkNDQ06fvy4du7cKelCAV+9erVeeOEFlZaWhlP8FVdcIY/HI0l68sknVVpaquuvv16BQEBbt25VX1+ftm3bFvO8KOIAAOuyyBGz6upqnTx5Ups3b9bg4KAKCwvV3t6uvLw8SdLg4GDEmfGXX35Z58+f17p167Ru3bpw+3333aeWlhZJ0hdffKEHH3xQfr9fHo9HS5YsUUdHh26++eaY5+UwjHgXFr6eQCAgj8ejVf/8E02fkTWZb40Uee9wQaqngEk2vyONHk6NcZ0/d1b/8tbjGh4ejmlvOR4Xa8WCF59UxhWxP/wkFqE/ndUfH34iKfOebCRxAIB1JfHu9HTAjW0AANgUSRwAYFkO48KV6DHTBUUcAGBdFrmxzapYTgcAwKZI4gAA6+LGNlMkcQAAbIokDgCwLvbETZHEAQCwKZI4AMC6SOKmSOIAANgUSRwAYF0kcVMUcQCAdXHEzBTL6QAA2BRJHABgWTw73RxJHAAAmyKJAwCsixvbTMWdxDs6OnTXXXdp/vz5cjgcevPNN5MwLQAAcDlxF/EzZ87oxhtv1C9/+ctkzAcAAMQo7uX0qqoqVVVVJWMuAAAgDuyJAwAsy6Ek3J2e2OFSKulFfGRkRCMjI+GfA4FAst8SAIApIelHzBobG+XxeMJXbm5ust8SAJAuLj6xLdFXmkh6EW9oaNDw8HD4GhgYSPZbAgDShZGkK00kfTnd6XTK6XQm+20AAJhy4i7ip0+f1u9///vwz8eOHVNfX59mz56thQsXJnRyAIApjoe9mIq7iH/wwQe67bbbwj/X19dLku677z61tLQkbGIAAMBc3EX81ltvlWGk0V9jAACWxRegmOMLUAAAsCke9gIAsC72xE2RxAEAsCmSOADAukjipijiAADL4sY2cyynAwBgUyRxAIB1JeNZ5zw7HQAApBpJHABgXdzYZookDgCATZHEAQCWxd3p5kjiAADYFEkcAGBd7ImbIokDAKzL+P9L6om6JlrEm5qalJ+fL5fLJa/Xq87OznH7vvHGG7r99tt19dVXy+12q6ysTPv374/qt3v3bhUUFMjpdKqgoEB79uyJa04UcQAALqOtrU11dXXasGGDent7tWzZMlVVVam/v3/M/h0dHbr99tvV3t6unp4e3XbbbbrrrrvU29sb7tPd3a3q6mrV1NToww8/VE1NjVatWqX3338/5nk5jEn+cvBAICCPx6NV//wTTZ+RNZlvjRR573BBqqeASTa/I43WKzGu8+fO6l/eelzDw8Nyu90JHftirbh2498r0+VK6NjBs2f1yVM/i2veJSUlKioqUnNzc7ht8eLFWrlypRobG2Ma4y/+4i9UXV2tn//855Kk6upqBQIBvf322+E+d9xxh2bNmqXW1taYxiSJAwCmpEAgEHGNjIyM2W90dFQ9PT2qrKyMaK+srFRXV1dM7xUKhXTq1CnNnj073Nbd3R015ooVK2IeU6KIAwCszEjSJSk3N1cejyd8jZeoh4aGFAwGlZ2dHdGenZ0tv98f08f4xS9+oTNnzmjVqlXhNr/f/7XGlLg7HQAwRQ0MDEQspzudTtP+DkfkM9cNw4hqG0tra6s2bdqkvXv3au7cuQkZ8yKKOADAspL5sBe32x3TnvicOXOUmZkZlZBPnDgRlaQv1dbWpjVr1uj111/X9773vYjf5eTkTGjMr2I5HQAAE1lZWfJ6vfL5fBHtPp9P5eXl476utbVV999/v3bt2qUf/OAHUb8vKyuLGvPAgQOmY16KJA4AwGXU19erpqZGxcXFKisr0/bt29Xf36/a2lpJUkNDg44fP66dO3dKulDAV69erRdeeEGlpaXhxH3FFVfI4/FIkh555BEtX75czzzzjO6++27t3btX77zzjg4dOhTzvEjiAADrSuKNbfGorq7Wli1btHnzZt10003q6OhQe3u78vLyJEmDg4MRZ8ZffvllnT9/XuvWrdO8efPC1yOPPBLuU15ertdee007duzQt7/9bbW0tKitrU0lJSUxz4skDgBADNauXau1a9eO+buWlpaIn999992Yxrznnnt0zz33THhOFHEAgGXxLWbmWE4HAMCmSOIAAGtLo+ScaCRxAABsiiQOALAuvk/cFEkcAACbIokDACyLu9PNUcQBANbFcropltMBALApkjgAwLJYTjdHEgcAwKZI4gAA62JP3BRJHAAAmyKJAwCsiyRuiiQOAIBNkcQBAJbF3enmKOIAAOtiOd0Uy+kAANgUSRwAYF0kcVMkcQAAbIokDgCwLG5sM0cSBwDApkjiAADrYk/cFEkcAACbIokDACyLPXFzFHEAgHWxnG6K5XQAAGyKJA4AsC6SuCmSOAAANkUSBwBYluPLK9FjpguSOAAANkUSBwBYF3viplJWxF/O7ZJ7JgsBU8HqVE8Ak+49FaR6CpgEobMO6a1Uz2JqI4kDACyLh72Yo4gDAKyL5XRTrGcDAGBTJHEAgLWlUXJONJI4AAA2RRIHAFgWN7aZI4kDAGBTJHEAgHVxd7opkjgAADFoampSfn6+XC6XvF6vOjs7x+07ODioe++9VzfccIMyMjJUV1cX1aelpUUOhyPqOnv2bMxzoogDACzr4p54oq94tbW1qa6uThs2bFBvb6+WLVumqqoq9ff3j9l/ZGREV199tTZs2KAbb7xx3HHdbrcGBwcjLpfLFfO8KOIAAOsyknTF6bnnntOaNWv0wAMPaPHixdqyZYtyc3PV3Nw8Zv9rrrlGL7zwglavXi2PxzPuuA6HQzk5ORFXPCjiAIApKRAIRFwjIyNj9hsdHVVPT48qKysj2isrK9XV1fW15nD69Gnl5eVpwYIFuvPOO9Xb2xvX6yniAADLSuZyem5urjweT/hqbGwccw5DQ0MKBoPKzs6OaM/Ozpbf75/wZ1u0aJFaWlq0b98+tba2yuVyqaKiQkePHo15DO5OBwBMSQMDA3K73eGfnU6naX+HwxHxs2EYUW3xKC0tVWlpafjniooKFRUV6cUXX9TWrVtjGoMiDgCwriQeMXO73RFFfDxz5sxRZmZmVOo+ceJEVDr/OjIyMrR06dK4kjjL6QAAmMjKypLX65XP54to9/l8Ki8vT9j7GIahvr4+zZs3L+bXkMQBANZlkYe91NfXq6amRsXFxSorK9P27dvV39+v2tpaSVJDQ4OOHz+unTt3hl/T19cn6cLNa59//rn6+vqUlZWlgoICSdKTTz6p0tJSXX/99QoEAtq6dav6+vq0bdu2mOdFEQcA4DKqq6t18uRJbd68WYODgyosLFR7e7vy8vIkXXi4y6VnxpcsWRL+556eHu3atUt5eXn69NNPJUlffPGFHnzwQfn9fnk8Hi1ZskQdHR26+eabY54XRRwAYFlW+gKUtWvXau3atWP+rqWlJarNMMzf6Pnnn9fzzz8/scl8iT1xAABsiiQOALAui+yJWxVFHABgWQ7DkOMyy9ITGTNdsJwOAIBNkcQBANbFcropkjgAADZFEgcAWJaVjphZEUkcAACbIokDAKyLPXFTJHEAAGyKJA4AsCz2xM1RxAEA1sVyuimW0wEAsCmSOADAslhON0cSBwDApkjiAADrYk/cFEkcAACbIokDACwtnfawE40kDgCATZHEAQDWZRgXrkSPmSYo4gAAy+KImTmW0wEAsCmSOADAujhiZookDgCATZHEAQCW5QhduBI9ZrogiQMAYFMkcQCAdbEnbookDgCATZHEAQCWxTlxcxRxAIB18cQ2UyynAwBgUyRxAIBlsZxujiQOAIBNkcQBANbFETNTJHEAAGyKJA4AsCz2xM2RxAEAsKm4inhjY6OWLl2qmTNnau7cuVq5cqU+/vjjZM0NADDVXTwnnugrTcRVxA8ePKh169bp8OHD8vl8On/+vCorK3XmzJlkzQ8AMIVdXE5P9JUu4toT/6d/+qeIn3fs2KG5c+eqp6dHy5cvT+jEAACAua91Y9vw8LAkafbs2QmZDAAAEThiZmrCN7YZhqH6+np95zvfUWFh4bj9RkZGFAgEIi4AAOymqalJ+fn5crlc8nq96uzsHLfv4OCg7r33Xt1www3KyMhQXV3dmP12796tgoICOZ1OFRQUaM+ePXHNacJFfP369frd736n1tZW036NjY3yeDzhKzc3d6JvCQCYYqyyJ97W1qa6ujpt2LBBvb29WrZsmaqqqtTf3z9m/5GREV199dXasGGDbrzxxjH7dHd3q7q6WjU1Nfrwww9VU1OjVatW6f3334/j348R/216Dz/8sN588011dHQoPz/ftO/IyIhGRkbCPwcCAeXm5uo//s+1cs/khNtUsPoP3C8x1bx3uCDVU8AkCJ09q/7HNmp4eFhutzuhYwcCAXk8HpWv2Kxp010JHfv8ubPq2v/zuOZdUlKioqIiNTc3h9sWL16slStXqrGx0fS1t956q2666SZt2bIlor26ulqBQEBvv/12uO2OO+7QrFmzLhuQL4qrihqGofXr1+uNN97Qb3/728sWcElyOp1yu90RFwAAMQkZybmkqK3erwbOrxodHVVPT48qKysj2isrK9XV1TXhj9bd3R015ooVK+IaM64ivm7dOv3617/Wrl27NHPmTPn9fvn9fv3pT3+KZxgAAFIuNzc3Yrt3vEQ9NDSkYDCo7OzsiPbs7Gz5/f4Jv7/f7//aY8Z1d/rFZYRbb701on3Hjh26//774xkKAIDLS+Ld6QMDAxGrw06n0/RlDocjchjDiGqL19cdM64iPoHtcwAAJsyhJDw7/cv/jHWLd86cOcrMzIxKyCdOnIhK0vHIycn52mNyZxkAACaysrLk9Xrl8/ki2n0+n8rLyyc8bllZWdSYBw4ciGtMvsUMAGBdyXjW+QTGq6+vV01NjYqLi1VWVqbt27erv79ftbW1kqSGhgYdP35cO3fuDL+mr69PknT69Gl9/vnn6uvrU1ZWlgoKLpzeeOSRR7R8+XI988wzuvvuu7V371698847OnToUMzzoogDAHAZ1dXVOnnypDZv3qzBwUEVFhaqvb1deXl5ki483OXSM+NLliwJ/3NPT4927dqlvLw8ffrpp5Kk8vJyvfbaa9q4caMef/xxXXfddWpra1NJSUnM86KIAwAsy0rfJ7527VqtXbt2zN+1tLREtcVyH9k999yje+65Z2ITEnviAADYFkkcAGBdfAGKKZI4AAA2RRIHAFiWwzDkSPDd6YkeL5Uo4gAA6wp9eSV6zDTBcjoAADZFEgcAWBbL6eZI4gAA2BRJHABgXRwxM0USBwDApkjiAADrssgXoFgVSRwAAJsiiQMALMtKX4BiRRRxAIB1sZxuiuV0AABsiiQOALAsR+jClegx0wVJHAAAmyKJAwCsiz1xUyRxAABsiiQOALAuHrtqiiQOAIBNkcQBAJbFV5GaI4kDAGBTJHEAgHVxd7opijgAwLoMSYl+OEv61HCW0wEAsCuSOADAsrixzRxJHAAAmyKJAwCsy1ASbmxL7HCpRBIHAMCmSOIAAOviiJkpkjgAADZFEgcAWFdIkiMJY6YJijgAwLI4YmaO5XQAAGyKJA4AsC5ubDNFEgcAwKZI4gAA6yKJmyKJAwBgUyRxAIB1kcRNkcQBALApijgAwLpCSbomoKmpSfn5+XK5XPJ6vers7DTtf/DgQXm9XrlcLl177bV66aWXIn7f0tIih8MRdZ09ezbmOVHEAQCWdfFhL4m+4tXW1qa6ujpt2LBBvb29WrZsmaqqqtTf3z9m/2PHjun73/++li1bpt7eXv3sZz/TT3/6U+3evTuin9vt1uDgYMTlcrlinhd74gAAXMZzzz2nNWvW6IEHHpAkbdmyRfv371dzc7MaGxuj+r/00ktauHChtmzZIklavHixPvjgAz377LP667/+63A/h8OhnJycCc+LJA4AsK6LN7Yl+pIUCAQirpGRkTGnMDo6qp6eHlVWVka0V1ZWqqura8zXdHd3R/VfsWKFPvjgA507dy7cdvr0aeXl5WnBggW688471dvbG9e/Hoo4AGBKys3NlcfjCV9jJWpJGhoaUjAYVHZ2dkR7dna2/H7/mK/x+/1j9j9//ryGhoYkSYsWLVJLS4v27dun1tZWuVwuVVRU6OjRozF/BpbTAQDWFTIkR4KPhIUujDcwMCC32x1udjqdpi9zOCK/Ts0wjKi2y/X/antpaalKS0vDv6+oqFBRUZFefPFFbd26NYYPQhEHAExRbrc7ooiPZ86cOcrMzIxK3SdOnIhK2xfl5OSM2X/atGm66qqrxnxNRkaGli5dGlcSZzkdAGBdSdwTj1VWVpa8Xq98Pl9Eu8/nU3l5+ZivKSsri+p/4MABFRcXa/r06eN8VEN9fX2aN29ezHOjiAMAcBn19fX61a9+pVdffVVHjhzRo48+qv7+ftXW1kqSGhoatHr16nD/2tpa/eEPf1B9fb2OHDmiV199Va+88or+5m/+JtznySef1P79+/XJJ5+or69Pa9asUV9fX3jMWLCcDgCwsCQ8dlXxj1ddXa2TJ09q8+bNGhwcVGFhodrb25WXlydJGhwcjDgznp+fr/b2dj366KPatm2b5s+fr61bt0YcL/viiy/04IMPyu/3y+PxaMmSJero6NDNN98c87wchpHwfzumhoeH9Wd/9mf6w/+6Ru5vsBAwFTw0MPZyE9LX4f+5KNVTwCQInT2rP256Sl988YU8Hk9Cxw4EAvJ4PPpe/sOalmF+w1m8zodG9M6xFzU8PBzTnriVTXoSP3XqlCQpr+jTyX5rpMwnqZ4AgCQ6depUwos4YjPpRXz+/PkaGBjQzJkzTW/NTzeBQEC5ublRRxqQnvjznlqm6p+3YRg6deqU5s+fn7w3CRmayPL35cdMD5NexDMyMrRgwYLJflvLiPVIA9IDf95Ty1T88yaBpxY3tgEArMsIXbgSPWaa4M4yAABsiiQ+SZxOp5544onLPtYP6YE/76mFP+8kmsDDWWIaM01M+hEzAAAuJ3zELPe/JueI2UAzR8wAAEgq7k43RREHAFgXy+mmuLENAACbIokDAKzLUBKSeGKHSyWS+CRoampSfn6+XC6XvF6vOjs7Uz0lJElHR4fuuusuzZ8/Xw6HQ2+++Waqp4QkaWxs1NKlSzVz5kzNnTtXK1eu1Mcff5zqaWGKoYgnWVtbm+rq6rRhwwb19vZq2bJlqqqqivi2G6SPM2fO6MYbb9Qvf/nLVE8FSXbw4EGtW7dOhw8fls/n0/nz51VZWakzZ86kemrpxQLfJ25lHDFLspKSEhUVFam5uTnctnjxYq1cuVKNjY0pnBmSzeFwaM+ePVq5cmWqp4JJ8Pnnn2vu3Lk6ePCgli9fnurp2F74iFnOg5qWkZXQsc+HRvWOf3taHDEjiSfR6Oioenp6VFlZGdFeWVmprq6uFM0KQDIMDw9LkmbPnp3imaSZUCg5V5qgiCfR0NCQgsGgsrOzI9qzs7Pl9/tTNCsAiWYYhurr6/Wd73xHhYWFqZ4OphDuTp8El37lqmEYU+prWIF0t379ev3ud7/ToUOHUj2V9MM5cVMU8SSaM2eOMjMzo1L3iRMnotI5AHt6+OGHtW/fPnV0dEzpr1lOGoq4KZbTkygrK0ter1c+ny+i3efzqby8PEWzApAIhmFo/fr1euONN/Tb3/5W+fn5qZ4SpiCSeJLV19erpqZGxcXFKisr0/bt29Xf36/a2tpUTw1JcPr0af3+978P/3zs2DH19fVp9uzZWrhwYQpnhkRbt26ddu3apb1792rmzJnhFTePx6MrrrgixbNLIzw73RRHzCZBU1OT/uEf/kGDg4MqLCzU888/zxGUNPXuu+/qtttui2q/77771NLSMvkTQtKMd1/Ljh07dP/990/uZNJQ+IjZ7P+SnCNm/3dHWhwxo4gDACznYhH/7qz7klLE//k//ltaFHH2xAEAsCn2xAEA1mUYid/DTqMFaJI4AAA2RRIHAFiXkYS709MoiVPEAQDWFQpJjgQ/69zg2ekAACDFSOIAAOtiOd0USRwAAJsiiQMALMsIhWQkeE/cYE8cAACkGkkcAGBd7ImbIokDAGBTJHEAgHWFDMlBEh8PRRwAYF2GISnRD3tJnyLOcjoAADZFEgcAWJYRMmQkeDndIIkDAIBUI4kDAKzLCCnxe+I87AUAAKQYRRwAYFlGyEjKNRFNTU3Kz8+Xy+WS1+tVZ2enaf+DBw/K6/XK5XLp2muv1UsvvRTVZ/fu3SooKJDT6VRBQYH27NkT15wo4gAAXEZbW5vq6uq0YcMG9fb2atmyZaqqqlJ/f/+Y/Y8dO6bvf//7WrZsmXp7e/Wzn/1MP/3pT7V79+5wn+7ublVXV6umpkYffvihampqtGrVKr3//vsxz8thpNNtegCAtBAIBOTxeHSr7tY0x/SEjn3eOKd3tVfDw8Nyu90xvaakpERFRUVqbm4Oty1evFgrV65UY2NjVP+//du/1b59+3TkyJFwW21trT788EN1d3dLkqqrqxUIBPT222+H+9xxxx2aNWuWWltbY5oXSRwAYFnndU7njQRfOifpwl8UvnqNjIyMOYfR0VH19PSosrIyor2yslJdXV1jvqa7uzuq/4oVK/TBBx/o3Llzpn3GG3Ms3J0OALCcrKws5eTk6JC/PSnjf+Mb31Bubm5E2xNPPKFNmzZF9R0aGlIwGFR2dnZEe3Z2tvx+/5jj+/3+MfufP39eQ0NDmjdv3rh9xhtzLBRxAIDluFwuHTt2TKOjo0kZ3zAMORyOiDan02n6mkv7jzXG5fpf2h7vmJeiiAMALMnlcsnlcqV6GpozZ44yMzOjEvKJEyeikvRFOTk5Y/afNm2arrrqKtM+4405FvbEAQAwkZWVJa/XK5/PF9Hu8/lUXl4+5mvKysqi+h84cEDFxcWaPn26aZ/xxhyTAQAATL322mvG9OnTjVdeecX46KOPjLq6OmPGjBnGp59+ahiGYTz22GNGTU1NuP8nn3xiXHnllcajjz5qfPTRR8Yrr7xiTJ8+3fjNb34T7vPee+8ZmZmZxtNPP20cOXLEePrpp41p06YZhw8fjnleFHEAAGKwbds2Iy8vz8jKyjKKioqMgwcPhn933333GbfccktE/3fffddYsmSJkZWVZVxzzTVGc3Nz1Jivv/66ccMNNxjTp083Fi1aZOzevTuuOXFOHAAAm2JPHAAAm6KIAwBgUxRxAABsiiIOAIBNUcQBALApijgAADZFEQcAwKYo4gAA2BRFHAAAm6KIAwBgUxRxAABs6v8B1/z82aBtCe0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_tensor(snapshots[2][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9072c98-8c6b-48dc-b01c-e14007e34744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[0.0000, 0.1111, 0.2222],\n",
       "          [0.1111, 0.2222, 0.3333],\n",
       "          [0.2222, 0.3333, 0.4444]],\n",
       " \n",
       "         [[0.4444, 0.3333, 0.2222],\n",
       "          [0.3333, 0.2222, 0.1111],\n",
       "          [0.2222, 0.1111, 0.0000]],\n",
       " \n",
       "         [[0.2222, 0.1111, 0.0000],\n",
       "          [0.3333, 0.2222, 0.1111],\n",
       "          [0.4444, 0.3333, 0.2222]],\n",
       " \n",
       "         [[0.2222, 0.3333, 0.4444],\n",
       "          [0.1111, 0.2222, 0.3333],\n",
       "          [0.0000, 0.1111, 0.2222]],\n",
       " \n",
       "         [[0.0000, 0.0000, 1.0000],\n",
       "          [0.0000, 0.0000, 1.0000],\n",
       "          [0.0000, 0.0000, 1.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [1.0000, 1.0000, 1.0000]],\n",
       " \n",
       "         [[0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000]]]),\n",
       " tensor([0.0200, 0.0240, 0.0000, 0.0240, 0.0240, 0.0000, 0.0440, 0.0240, 0.0000,\n",
       "         0.0200, 0.0240, 0.0240, 0.0240, 0.0740, 0.0260, 0.0000, 0.0000, 0.0000]),\n",
       " tensor([0.2000, 0.4480, 0.0000, 0.0000]),\n",
       " tensor([1.])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e2a186-0104-4495-b63d-150a2074fca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss in epoch 0 of generation 1: 0.12040106638762495 + 0.13458752629413784 = 0.25498859268176277.\n",
      "Evaluation loss in epoch 0 of generation 1: 0.11795403501291009 + 0.1170065313120169 = 0.234960566324927.\n",
      "Training loss in epoch 1 of generation 1: 0.12840064112462793 + 1.0217612264748044 = 1.1501618675994325.\n",
      "Evaluation loss in epoch 1 of generation 1: 0.13682486475939862 + 1.8491846701432 = 1.9860095349025986.\n",
      "Training loss in epoch 2 of generation 1: 0.1364523731744827 + 1.8756484405967824 = 2.0121008137712653.\n",
      "Evaluation loss in epoch 2 of generation 1: 0.13682486475939862 + 1.815412631404685 = 1.9522374961640836.\n",
      "Training loss in epoch 3 of generation 1: 0.1364523734001878 + 1.8491526475883047 = 1.9856050209884926.\n",
      "Evaluation loss in epoch 3 of generation 1: 0.13682486475939862 + 1.815412631404685 = 1.9522374961640836.\n",
      "Training loss in epoch 4 of generation 1: 0.1364523731609157 + 1.8491526475883047 = 1.9856050207492204.\n",
      "Evaluation loss in epoch 4 of generation 1: 0.13682486475939862 + 1.815412631404685 = 1.9522374961640836.\n",
      "Training loss in epoch 5 of generation 1: 0.1364523734186882 + 1.8491526475883047 = 1.9856050210069929.\n",
      "Evaluation loss in epoch 5 of generation 1: 0.13682486475939862 + 1.815412631404685 = 1.9522374961640836.\n",
      "Training loss in epoch 6 of generation 1: 0.1364523731239149 + 1.8491526475883047 = 1.9856050207122196.\n",
      "Evaluation loss in epoch 6 of generation 1: 0.13682486499621865 + 1.815412631404685 = 1.9522374964009037.\n",
      "Training loss in epoch 7 of generation 1: 0.13645548976466457 + 1.8491526475883047 = 1.9856081373529693.\n",
      "Evaluation loss in epoch 7 of generation 1: 0.1368248619964981 + 1.815412631404685 = 1.9522374934011832.\n",
      "Training loss in epoch 8 of generation 1: 0.13140453011846473 + 1.4097490854476766 = 1.5411536155661414.\n",
      "Evaluation loss in epoch 8 of generation 1: 0.1180514842900858 + 0.11005122517426374 = 0.22810270946434955.\n",
      "Training loss in epoch 9 of generation 1: 0.1123396043133454 + 0.10413779306949134 = 0.21647739738283672.\n",
      "Evaluation loss in epoch 9 of generation 1: 0.11171278560036273 + 0.10438279936831871 = 0.21609558496868145.\n",
      "Training loss in epoch 10 of generation 1: 0.11112229066461736 + 0.09847203377254027 = 0.20959432443715761.\n",
      "Evaluation loss in epoch 10 of generation 1: 0.11116127489852684 + 0.09850179613858903 = 0.20966307103711587.\n",
      "Training loss in epoch 11 of generation 1: 0.11074899919556933 + 0.09320182661081954 = 0.20395082580638885.\n",
      "Evaluation loss in epoch 11 of generation 1: 0.11092340041347593 + 0.09833844091785476 = 0.2092618413313307.\n",
      "Training loss in epoch 12 of generation 1: 0.11044755292086292 + 0.09246772193620043 = 0.20291527485706334.\n",
      "Evaluation loss in epoch 12 of generation 1: 0.11140549343732126 + 0.08730296507602954 = 0.1987084585133508.\n",
      "Training loss in epoch 13 of generation 1: 0.1104802115547602 + 0.09184930455555128 = 0.20232951611031147.\n",
      "Evaluation loss in epoch 13 of generation 1: 0.11084603181827464 + 0.0915614754361197 = 0.20240750725439433.\n",
      "Training loss in epoch 14 of generation 1: 0.11003579735610383 + 0.0914529180885549 = 0.20148871544465874.\n",
      "Evaluation loss in epoch 14 of generation 1: 0.10991000221340223 + 0.08911920259867408 = 0.1990292048120763.\n",
      "Training loss in epoch 15 of generation 1: 0.10927604567660007 + 0.08836905575209046 = 0.19764510142869054.\n",
      "Evaluation loss in epoch 15 of generation 1: 0.10854824208412016 + 0.08513065287454043 = 0.19367889495866059.\n",
      "Training loss in epoch 16 of generation 1: 0.10870210690203036 + 0.08939233010226884 = 0.1980944370042992.\n",
      "Evaluation loss in epoch 16 of generation 1: 0.10847039313893002 + 0.08637540992640785 = 0.19484580306533789.\n",
      "Training loss in epoch 17 of generation 1: 0.10772765511218467 + 0.08792201117626779 = 0.19564966628845246.\n",
      "Evaluation loss in epoch 17 of generation 1: 0.1080641378660528 + 0.0863079057616177 = 0.1943720436276705.\n",
      "Training loss in epoch 18 of generation 1: 0.1080997568156897 + 0.08957730924328405 = 0.19767706605897375.\n",
      "Evaluation loss in epoch 18 of generation 1: 0.10759604059103635 + 0.08303668151829537 = 0.19063272210933171.\n",
      "Training loss in epoch 19 of generation 1: 0.10702250134896321 + 0.08665543581194955 = 0.19367793716091278.\n",
      "Evaluation loss in epoch 19 of generation 1: 0.10668770172236604 + 0.08393221843070951 = 0.19061992015307555.\n",
      "Training loss in epoch 20 of generation 1: 0.10692184089610363 + 0.08727751078793795 = 0.19419935168404157.\n",
      "Evaluation loss in epoch 20 of generation 1: 0.10743887812656516 + 0.0878986084096608 = 0.19533748653622596.\n",
      "Training loss in epoch 21 of generation 1: 0.10704892445171035 + 0.08786466160565508 = 0.19491358605736545.\n",
      "Evaluation loss in epoch 21 of generation 1: 0.10700213886453916 + 0.08429452723747709 = 0.19129666610201623.\n",
      "Training loss in epoch 22 of generation 1: 0.10633077121480014 + 0.08573979993813141 = 0.19207057115293155.\n",
      "Evaluation loss in epoch 22 of generation 1: 0.10653474016918192 + 0.08789488906807832 = 0.19442962923726023.\n",
      "Training loss in epoch 23 of generation 1: 0.10672886716287659 + 0.08650776713733174 = 0.19323663430020832.\n",
      "Evaluation loss in epoch 23 of generation 1: 0.10697942774339816 + 0.08445041076023545 = 0.1914298385036336.\n",
      "Training loss in epoch 24 of generation 1: 0.10616668336605116 + 0.08540171115875074 = 0.1915683945248019.\n",
      "Evaluation loss in epoch 24 of generation 1: 0.10678858931081775 + 0.08376404592364486 = 0.19055263523446261.\n",
      "Training loss in epoch 25 of generation 1: 0.10644225911464411 + 0.08631193267060994 = 0.19275419178525405.\n",
      "Evaluation loss in epoch 25 of generation 1: 0.106709639586594 + 0.08844113556700386 = 0.19515077515359786.\n",
      "Training loss in epoch 26 of generation 1: 0.1062400861228672 + 0.08462601451640954 = 0.19086610063927675.\n",
      "Evaluation loss in epoch 26 of generation 1: 0.10621994613920277 + 0.0807296324614736 = 0.18694957860067637.\n",
      "Training loss in epoch 27 of generation 1: 0.10737480629047187 + 0.0906158088681516 = 0.19799061515862348.\n",
      "Evaluation loss in epoch 27 of generation 1: 0.10744273466203852 + 0.08954010451718697 = 0.1969828391792255.\n",
      "Training loss in epoch 28 of generation 1: 0.10637750973319529 + 0.08719676663697253 = 0.19357427637016783.\n",
      "Evaluation loss in epoch 28 of generation 1: 0.10626832342199138 + 0.08775595608318831 = 0.1940242795051797.\n",
      "Training loss in epoch 29 of generation 1: 0.10652109239271466 + 0.0860200461449533 = 0.19254113853766797.\n",
      "Evaluation loss in epoch 29 of generation 1: 0.10815569403431843 + 0.08744527193062472 = 0.19560096596494317.\n",
      "Training loss in epoch 30 of generation 1: 0.10672672299656746 + 0.08594864585321657 = 0.19267536884978403.\n",
      "Evaluation loss in epoch 30 of generation 1: 0.10792378042818014 + 0.08424973366607075 = 0.1921735140942509.\n",
      "Trainig was interrupted.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    for epoch in range(1000):\n",
    "        total_kl_loss = 0\n",
    "        total_mse_loss = 0\n",
    "        for states, wall_priors, step_priors, values in training_loader:\n",
    "            states = states.to(device)\n",
    "            wall_priors = wall_priors.to(device)\n",
    "            step_priors = step_priors.to(device)\n",
    "            values = values.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            wp, sp, vs = model.forward(states)\n",
    "            kl_loss, mse_loss = loss_fn(wp, sp, vs, wall_priors, step_priors, values)\n",
    "            total_kl_loss += float(kl_loss)\n",
    "            total_mse_loss += float(mse_loss)\n",
    "\n",
    "            loss = kl_loss + mse_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "        print(\n",
    "            f\"Training loss in epoch {epoch} of generation {generation}: {total_kl_loss / len(training_data)} + {total_mse_loss / len(training_data)} = {(total_kl_loss + total_mse_loss) / len(training_data)}.\"\n",
    "        )\n",
    "        \n",
    "        model.train(False)\n",
    "        total_kl_loss = 0\n",
    "        total_mse_loss = 0\n",
    "        for states, wall_priors, step_priors, values in eval_loader:\n",
    "            states = states.to(device)\n",
    "            wall_priors = wall_priors.to(device)\n",
    "            step_priors = step_priors.to(device)\n",
    "            values = values.to(device)\n",
    "            wp, sp, vs = model.forward(states)\n",
    "            kl_loss, mse_loss = loss_fn(wp, sp, vs, wall_priors, step_priors, values)\n",
    "            total_kl_loss += float(kl_loss)\n",
    "            total_mse_loss += float(mse_loss)\n",
    "        print(\n",
    "            f\"Evaluation loss in epoch {epoch} of generation {generation}: {total_kl_loss / len(eval_data)} + {total_mse_loss / len(eval_data)} = {(total_kl_loss + total_mse_loss) / len(eval_data)}.\"\n",
    "        )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Trainig was interrupted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ced9ae19-cfea-4b36-9f0b-52d55b3379ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = torch.unsqueeze(snapshots[0][0], 0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da072fb-1e1b-4c9e-bb6b-9f607d1859ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.3669e-04, 6.8333e-12, 9.3426e-12, 2.3319e-12, 3.1439e-12, 9.1561e-12,\n",
       "          2.7555e-11, 3.3933e-07, 8.5234e-12, 1.3690e-06, 8.1702e-10, 2.3860e-12,\n",
       "          3.5768e-10, 1.6445e-19, 7.3545e-11, 9.4305e-12, 9.1262e-12, 9.4213e-12]],\n",
       "        device='cuda:0', grad_fn=<SigmoidBackward0>),\n",
       " tensor([[9.9592e-01, 9.9970e-01, 1.9444e-09, 3.9429e-06]], device='cuda:0',\n",
       "        grad_fn=<SigmoidBackward0>),\n",
       " tensor([[0.9198]], device='cuda:0', grad_fn=<TanhBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7d7d78a-a365-49db-acd5-9457152eb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, models_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
