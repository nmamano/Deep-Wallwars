{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7de520-7e2d-46a8-9801-c8447f673484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import torch.onnx\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from model import ResNet\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "columns = 5\n",
    "rows = 5\n",
    "channels = 64\n",
    "layers = 15\n",
    "epochs = 100\n",
    "training_batch_size = 64\n",
    "inference_batch_size = 256\n",
    "kl_loss_scale = 0.1\n",
    "\n",
    "data_folder = \"../data\"\n",
    "models_folder = \"../models\"\n",
    "generation = 1\n",
    "\n",
    "class Snapshots(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_name):\n",
    "        self.data = [[], [], [], []]\n",
    "        i = 0\n",
    "        with open(file_name) as f:\n",
    "            for line in f.readlines():\n",
    "                if line.strip() == \"\":\n",
    "                    i = 0\n",
    "                    continue\n",
    "\n",
    "                t = torch.tensor([float(x) for x in line.split(\", \")])\n",
    "\n",
    "                if i == 0:\n",
    "                    t = t.view(7, columns, rows)\n",
    "                self.data[i].append(t)\n",
    "                i += 1\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data[0])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return [self.data[x][index] for x in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17deff99-8d43-42c5-998d-3a2a018cc1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(wp_out, sp_out, vs_out, wp_label, sp_label, vs_label):\n",
    "    kl_div = nn.KLDivLoss(reduction='sum')\n",
    "    mse = nn.MSELoss(reduction='sum')\n",
    "    \n",
    "    # Concatenate the outputs to form the complete action distribution\n",
    "    actions_out = torch.cat([wp_out, sp_out], dim=1)\n",
    "    # Apply log_softmax to convert to log probabilities\n",
    "    log_probs = F.log_softmax(actions_out, dim=1)\n",
    "    \n",
    "    # Concatenate the labels to form the complete target distribution\n",
    "    actions_label = torch.cat([wp_label, sp_label], dim=1)\n",
    "    \n",
    "    # Compute the KL divergence loss\n",
    "    kl_loss = kl_loss_scale * kl_div(log_probs, actions_label)\n",
    "    \n",
    "    # Compute the MSE loss for the scalar output\n",
    "    mse_loss = mse(vs_out, vs_label)\n",
    "\n",
    "    return (kl_loss, mse_loss)\n",
    "\n",
    "\n",
    "def save_model(model, folder):\n",
    "    torch.save(model, f\"{folder}/model_{generation}.pt\")\n",
    "    input_names = [\"States\"]\n",
    "    output_names = [\"WallPriors\", \"StepPriors\", \"Values\"]\n",
    "    dummy_input = torch.randn(inference_batch_size, 7, columns, rows).to(device)\n",
    "    torch.onnx.export(\n",
    "        model,\n",
    "        dummy_input,\n",
    "        f\"{folder}/model_{generation}.onnx\",\n",
    "        input_names=input_names,\n",
    "        output_names=output_names,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba22da-d7c8-4214-9b14-102331726bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(columns, rows, channels, layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cae0251-928b-44eb-bfb2-4a400bba1adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_window = range((generation - 1) // 2, generation)\n",
    "snapshots = torch.utils.data.ConcatDataset(\n",
    "    [Snapshots(f\"{data_folder}/snapshots_{i}.csv\") for i in training_window]\n",
    ")\n",
    "training_data, eval_data = torch.utils.data.random_split(snapshots, [0.8, 0.2])\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    training_data,\n",
    "    batch_size=training_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "eval_loader = torch.utils.data.DataLoader(\n",
    "    eval_data,\n",
    "    batch_size=training_batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c56510-de5b-4897-bda8-d95fd99ad212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_tensor(mat, cmap='viridis'):\n",
    "    \"\"\"\n",
    "    Plots a 2D PyTorch tensor as an n x n grid of squares with colors representing the tensor values.\n",
    "\n",
    "    Parameters:\n",
    "    - mat: 2D PyTorch tensor of floats.\n",
    "    - cmap: Colormap for visualizing the values in the tensor.\n",
    "    \"\"\"\n",
    "    # Ensure mat is a 2D tensor\n",
    "    if mat.dim() != 2:\n",
    "        raise ValueError(\"Input tensor must be 2D\")\n",
    "\n",
    "    # Convert the tensor to a NumPy array\n",
    "    matrix = mat.numpy()\n",
    "\n",
    "    # Plotting the matrix\n",
    "    plt.figure(figsize=(6,6))  # Adjust the figure size as needed\n",
    "    plt.imshow(matrix, cmap=cmap, interpolation='nearest')  # Use specified colormap\n",
    "    plt.colorbar()  # Show color scale\n",
    "    plt.xticks(range(matrix.shape[0]))  # Adjust ticks based on tensor size\n",
    "    plt.yticks(range(matrix.shape[1]))\n",
    "    plt.grid(False)  # Turn off the grid\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a3b40-e684-4e6c-a626-7aa278ac4bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tensor(snapshots[3][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9072c98-8c6b-48dc-b01c-e14007e34744",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(snapshots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e2a186-0104-4495-b63d-150a2074fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "try:\n",
    "    for epoch in range(1000):\n",
    "        total_kl_loss = 0\n",
    "        total_mse_loss = 0\n",
    "        for states, wall_priors, step_priors, values in training_loader:\n",
    "            states = states.to(device)\n",
    "            wall_priors = wall_priors.to(device)\n",
    "            step_priors = step_priors.to(device)\n",
    "            values = values.to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            wp, sp, vs = model.forward(states)\n",
    "            kl_loss, mse_loss = loss_fn(wp, sp, vs, wall_priors, step_priors, values)\n",
    "            total_kl_loss += float(kl_loss)\n",
    "            total_mse_loss += float(mse_loss)\n",
    "\n",
    "            loss = kl_loss + mse_loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            del loss\n",
    "        print(\n",
    "            f\"Training loss in epoch {epoch} of generation {generation}: {total_kl_loss / len(training_data)} + {total_mse_loss / len(training_data)} = {(total_kl_loss + total_mse_loss) / len(training_data)}.\"\n",
    "        )\n",
    "        \n",
    "        model.train(False)\n",
    "        total_kl_loss = 0\n",
    "        total_mse_loss = 0\n",
    "        for states, wall_priors, step_priors, values in eval_loader:\n",
    "            states = states.to(device)\n",
    "            wall_priors = wall_priors.to(device)\n",
    "            step_priors = step_priors.to(device)\n",
    "            values = values.to(device)\n",
    "            wp, sp, vs = model.forward(states)\n",
    "            kl_loss, mse_loss = loss_fn(wp, sp, vs, wall_priors, step_priors, values)\n",
    "            total_kl_loss += float(kl_loss)\n",
    "            total_mse_loss += float(mse_loss)\n",
    "        print(\n",
    "            f\"Evaluation loss in epoch {epoch} of generation {generation}: {total_kl_loss / len(eval_data)} + {total_mse_loss / len(eval_data)} = {(total_kl_loss + total_mse_loss) / len(eval_data)}.\"\n",
    "        )\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Trainig was interrupted.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced9ae19-cfea-4b36-9f0b-52d55b3379ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = torch.unsqueeze(snapshots[0][0], 0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da072fb-1e1b-4c9e-bb6b-9f607d1859ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forward(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d7d78a-a365-49db-acd5-9457152eb041",
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshots[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0d688b-ef5b-49dd-8c45-d957dd7b5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, models_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8235c-6e6a-4dcb-831e-607a94055a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
